{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n# Step 1: Load the dataset from Kaggle input directory\ndata = pd.read_csv('/kaggle/input/house-price-dataset-of-india/House Price India.csv')\n# Step 2: Data Preprocessing\n# Fill missing values with the mean of the respective columns\ndata.fillna(data.mean(), inplace=True)\n# Step 3: Check if the required columns are present\nrequired_columns = ['Locality', 'Type']\nif all(column in data.columns for column in required_columns):\n    # Convert categorical features to numerical using one-hot encoding\n    data = pd.get_dummies(data, columns=required_columns)\nelse:\n    # Handle the case when 'Locality' and 'Type' columns are missing\n    print(\"Required columns 'Locality' and/or 'Type' are missing.\")\n# Step 4: Feature Engineering (if needed)\n# Select relevant features that can affect house prices.\n# For this example, let's assume we have features like 'Area', 'Rooms', 'Bathroom', 'Parking', etc.\n# Step 5: Data Splitting\nX = data.drop('Price', axis=1)  # Features (excluding the target variable 'Price')\ny = data['Price']  # Target variable 'Price'\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Step 6: Model Selection and Training\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n# Step 7: Model Evaluation\ny_pred = model.predict(X_test)\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\npredicted_prices = pd.Series(y_pred, name='Predicted Price')\n# Display the first few predicted prices\nprint(predicted_prices.head())\nprint(f'Mean Absolute Error (MAE): {mae}')\nprint(f'Mean Squared Error (MSE): {mse}')\nprint(f'Root Mean Squared Error (RMSE): {rmse}')\n# Step 8: Hyperparameter Tuning (optional)\n# You can use GridSearchCV or RandomizedSearchCV to find optimal hyperparameters\n# Step 9: Model Deployment (optional)\n# Use the trained model to make predictions on new data\n# Step 10: Model Monitoring and Maintenance (optional)\n# Continuously monitor and update the model as needed","metadata":{"execution":{"iopub.status.busy":"2023-08-12T12:28:07.057544Z","iopub.execute_input":"2023-08-12T12:28:07.058003Z","iopub.status.idle":"2023-08-12T12:28:21.772576Z","shell.execute_reply.started":"2023-08-12T12:28:07.057965Z","shell.execute_reply":"2023-08-12T12:28:21.771301Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Required columns 'Locality' and/or 'Type' are missing.\n0    234249.50\n1    555481.68\n2    616145.70\n3    553435.86\n4    640771.32\nName: Predicted Price, dtype: float64\nMean Absolute Error (MAE): 16104.31597127223\nMean Squared Error (MSE): 5839667675.932813\nRoot Mean Squared Error (RMSE): 76417.71833765264\n","output_type":"stream"}]}]}